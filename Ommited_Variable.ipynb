{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Matthias Müllner\n",
    "\n",
    "## University of Graz\n",
    "## Center for Accounting Research\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ommited Variable Bias\n",
    "\n",
    "<br>\n",
    "\n",
    "Here i create two orthogonal vectors. Those two vectors are independent variables of a multiple linear regression. Since they are orthogonal their correlation is zero. I aim to show that omission of an independet variable does not lead to any bias if those are uncorrelated.\n",
    "\n",
    "In a second step I will do the same stuff for correlation between the dependent and the omitted independent variable. Still coefficients should be unbiased if these verctors are orthogonal, however my R² and my standard error should increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exogeneous Vraibale X1 [0.5014143247653111, 0.5726030348786466, 0.7443780928800537]\n",
      "Exogeneous Vraibale X2 [0.0, -0.7443780928800537, 0.5726030348786466]\n",
      "Inner Product of X1 and X2 =  0.0\n",
      "Matrix containing of my exogeneous Variables X1 and X2 in columns: \n",
      " [[ 0.50141432  0.        ]\n",
      " [ 0.57260303 -0.74437809]\n",
      " [ 0.74437809  0.57260303]] \n",
      "\n",
      "Estimates of Regressession Coefficients only including X1\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.075\n",
      "Model:                            OLS   Adj. R-squared:                 -0.387\n",
      "Method:                 Least Squares   F-statistic:                    0.1632\n",
      "Date:                Mon, 15 Jul 2019   Prob (F-statistic):              0.725\n",
      "Time:                        09:10:05   Log-Likelihood:                -4.4069\n",
      "No. Observations:                   3   AIC:                             10.81\n",
      "Df Residuals:                       2   BIC:                             9.912\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.4886      1.209     -0.404      0.725      -5.692       4.715\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   2.875\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.426\n",
      "Skew:                          -0.539   Prob(JB):                        0.808\n",
      "Kurtosis:                       1.500   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Estimates of Regressession Coefficients including X1 and X2\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.958\n",
      "Model:                            OLS   Adj. R-squared:                  0.874\n",
      "Method:                 Least Squares   F-statistic:                     11.41\n",
      "Date:                Mon, 15 Jul 2019   Prob (F-statistic):              0.205\n",
      "Time:                        09:10:05   Log-Likelihood:                0.23158\n",
      "No. Observations:                   3   AIC:                             3.537\n",
      "Df Residuals:                       1   BIC:                             1.734\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.4886      0.364     -1.341      0.408      -5.119       4.142\n",
      "x2             1.8944      0.413      4.586      0.137      -3.355       7.144\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.375\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.523\n",
      "Skew:                           0.695   Prob(JB):                        0.770\n",
      "Kurtosis:                       1.500   Cond. No.                         1.13\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Matrix containing of my exogeneous Variables X1 and X3 in columns: \n",
      " [[ 0.50141432  0.76202313]\n",
      " [ 0.57260303 -0.13601364]\n",
      " [ 0.74437809 -1.05554817]] \n",
      "\n",
      "Inner Product of X1 and X3 =  -0.481519440867104\n",
      "Estimates of Regressession Coefficients including X1 and X2\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.126\n",
      "Model:                            OLS   Adj. R-squared:                 -1.621\n",
      "Method:                 Least Squares   F-statistic:                   0.07226\n",
      "Date:                Mon, 15 Jul 2019   Prob (F-statistic):              0.935\n",
      "Time:                        09:10:05   Log-Likelihood:                -4.3221\n",
      "No. Observations:                   3   AIC:                             12.64\n",
      "Df Residuals:                       1   BIC:                             10.84\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.6363      1.772     -0.359      0.781     -23.150      21.878\n",
      "x2            -0.3475      1.441     -0.241      0.849     -18.659      17.964\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   2.995\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.531\n",
      "Skew:                          -0.707   Prob(JB):                        0.767\n",
      "Kurtosis:                       1.500   Cond. No.                         1.52\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.local/lib/python3.7/site-packages/statsmodels/stats/stattools.py:72: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n",
      "/home/matthias/.local/lib/python3.7/site-packages/statsmodels/stats/stattools.py:72: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n",
      "/home/matthias/.local/lib/python3.7/site-packages/statsmodels/stats/stattools.py:72: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking for omitted variable bias\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS  \n",
    "\n",
    "X = np.zeros((2,3))\n",
    "list_x1 = [] # first independent variable\n",
    "list_x2 = []\n",
    "list_x3 = []\n",
    "list_y = []\n",
    "list_k = [1.0] # dummy vector to create orthogonal vector\n",
    "\n",
    "\n",
    "for i in range(0, 2): # dummy vectore [1,0,0] identity vector\n",
    "    list_k.append(0)\n",
    "\n",
    "\n",
    "for i in range(0, 3):  #random vector x1\n",
    "    x1 = np.random.normal(0, 1)\n",
    "    list_x1.append(x1)\n",
    "\n",
    "\n",
    "for i in range(0, 3): #random vector x3\n",
    "    x3 = np.random.normal(0, 1)\n",
    "    list_x3.append(x3)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Cross product of my dummy vector and vector of independent variables creates an orthogonal vector\n",
    "to my fist independent vatiable.\n",
    "\"\"\"\n",
    "\n",
    "x2 = np.cross(list_k, list_x1) # orthogonal vector to x1\n",
    "\n",
    "\"\"\"\n",
    "Unfortunately the output of np.dot is not suitable to get used in statsmodel got to convert to\n",
    "have a proper list\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(x2)):\n",
    "    list_x2.append(x2[i])\n",
    "    \n",
    "print(\"Exogeneous Vraibale X1\",list_x1)\n",
    "print(\"Exogeneous Vraibale X2\",list_x2)\n",
    "\n",
    "\n",
    "inner_product = np.dot(list_x1,list_x2) #check whether inner product is zero --> Orthogonality\n",
    "print(\"Inner Product of X1 and X2 = \",inner_product)\n",
    "list_y = np.random.randn(3) # create my dependent variable which is just some random vector.\n",
    "#print(list_y)\n",
    "\n",
    "for k in range(len(list_x1)):\n",
    "    X[0][k] = list_x1[k]\n",
    "\n",
    "for k in range(len(list_x2)):\n",
    "    X[1][k] = list_x2[k]\n",
    "\n",
    "X = X.transpose()\n",
    "print(\"Matrix containing of my exogeneous Variables X1 and X2 in columns: \\n\",X,\"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Computing the Regression with only x1\n",
    "\"\"\"\n",
    "\n",
    "print(\"Estimates of Regressession Coefficients only including X1\\n\")\n",
    "#list_x1 = sm.add_constant(list_x1)\n",
    "model = sm.OLS(list_y,list_x1).fit()\n",
    "predictions = model.predict()\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Computing the Regression with x1 and x2 included\n",
    "\"\"\"\n",
    "print(\"Estimates of Regressession Coefficients including X1 and X2\\n\")\n",
    "#X = sm.add_constant(X)\n",
    "model = sm.OLS(list_y,X).fit()\n",
    "predictions = model.predict()\n",
    "print(model.summary())\n",
    "\n",
    "X = X.transpose()\n",
    "for k in range(len(list_x3)):\n",
    "    X[1][k] = list_x3[k]\n",
    "\n",
    "X = X.transpose()\n",
    "print(\"Matrix containing of my exogeneous Variables X1 and X3 in columns: \\n\",X,\"\\n\")\n",
    "\n",
    "\n",
    "inner_product = np.dot(list_x1,list_x3) #check whether inner product is zero --> Orthogonality\n",
    "print(\"Inner Product of X1 and X3 = \",inner_product)\n",
    "\n",
    "print(\"Estimates of Regressession Coefficients including X1 and X2\\n\")\n",
    "#X = sm.add_constant(X)\n",
    "model = sm.OLS(list_y,X).fit()\n",
    "predictions = model.predict()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
