{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Matthias Müllner\n",
    "\n",
    "## University of Graz\n",
    "## Center for Accounting Research\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ommited Variable Bias\n",
    "\n",
    "<br>\n",
    "\n",
    "Here i create two orthogonal vectors. Those two vectors are independent variables of a multiple linear regression. Since they are orthogonal their correlation is zero. I aim to show that omission of an independet variable does not lead to any bias if those are uncorrelated.\n",
    "\n",
    "In a second step I will do the same stuff for correlation between the dependent and the omitted independent variable. Still coefficients should be unbiased if these verctors are orthogonal, however my R² and my standard error should increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exogeneous Vraibale X1 [-0.36726337165520667, 1.295514939351434, -1.7042769535453595]\n",
      "Exogeneous Vraibale X2 [-0.0, 1.7042769535453595, 1.295514939351434]\n",
      "Inner Product of X1 and X2 =  0.0\n",
      "Matrix containing of my exogeneous Variables X1 and X2 in columns: \n",
      " [[-0.36726337 -0.        ]\n",
      " [ 1.29551494  1.70427695]\n",
      " [-1.70427695  1.29551494]] \n",
      "\n",
      "Estimates of Regressession Coefficients only including X1\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.181\n",
      "Model:                            OLS   Adj. R-squared:                 -0.229\n",
      "Method:                 Least Squares   F-statistic:                    0.4406\n",
      "Date:                Fri, 12 Jul 2019   Prob (F-statistic):              0.575\n",
      "Time:                        10:27:50   Log-Likelihood:                -2.6885\n",
      "No. Observations:                   3   AIC:                             7.377\n",
      "Df Residuals:                       2   BIC:                             6.476\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.2219      0.334     -0.664      0.575      -1.660       1.216\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.356\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.517\n",
      "Skew:                          -0.686   Prob(JB):                        0.772\n",
      "Kurtosis:                       1.500   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Estimates of Regressession Coefficients including X1 and X2\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.374\n",
      "Model:                            OLS   Adj. R-squared:                 -0.879\n",
      "Method:                 Least Squares   F-statistic:                    0.2983\n",
      "Date:                Fri, 12 Jul 2019   Prob (F-statistic):              0.791\n",
      "Time:                        10:27:50   Log-Likelihood:                -2.2853\n",
      "No. Observations:                   3   AIC:                             8.571\n",
      "Df Residuals:                       1   BIC:                             6.768\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.2219      0.413     -0.537      0.686      -5.474       5.030\n",
      "x2             0.2329      0.419      0.555      0.677      -5.096       5.561\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   0.836\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.450\n",
      "Skew:                          -0.581   Prob(JB):                        0.798\n",
      "Kurtosis:                       1.500   Cond. No.                         1.01\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Matrix containing of my exogeneous Variables X1 and X3 in columns: \n",
      " [[-0.36726337  0.79859081]\n",
      " [ 1.29551494  0.79859081]\n",
      " [-1.70427695  0.79859081]] \n",
      "\n",
      "Inner Product of X1 and X3 =  -0.6197267427489236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.local/lib/python3.7/site-packages/statsmodels/stats/stattools.py:72: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n",
      "/home/matthias/.local/lib/python3.7/site-packages/statsmodels/stats/stattools.py:72: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking for omitted variable bias\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS  \n",
    "\n",
    "X = np.zeros((2,3))\n",
    "list_x1 = [] # first independent variable\n",
    "list_x2 = []\n",
    "list_x3 = []\n",
    "list_y = []\n",
    "list_k = [1.0] # dummy vector to create orthogonal vector\n",
    "\n",
    "\n",
    "for i in range(0, 2): # dummy vectore [1,0,0] identity vector\n",
    "    list_k.append(0)\n",
    "\n",
    "\n",
    "for i in range(0, 3):  #random vector x1\n",
    "    x1 = np.random.normal(0, 1)\n",
    "    list_x1.append(x1)\n",
    "\n",
    "\n",
    "for i in range(0, 3): #random vector x3\n",
    "    x1 = np.random.normal(0, 1)\n",
    "    list_x3.append(x3)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Cross product of my dummy vector and vector of independent variables creates an orthogonal vector\n",
    "to my fist independent vatiable.\n",
    "\"\"\"\n",
    "\n",
    "x2 = np.cross(list_k, list_x1) # orthogonal vector to x1\n",
    "\n",
    "\"\"\"\n",
    "Unfortunately the output of np.dot is not suitable to get used in statsmodel got to convert to\n",
    "have a proper list\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(x2)):\n",
    "    list_x2.append(x2[i])\n",
    "    \n",
    "print(\"Exogeneous Vraibale X1\",list_x1)\n",
    "print(\"Exogeneous Vraibale X2\",list_x2)\n",
    "\n",
    "\n",
    "inner_product = np.dot(list_x1,list_x2) #check whether inner product is zero --> Orthogonality\n",
    "print(\"Inner Product of X1 and X2 = \",inner_product)\n",
    "list_y = np.random.randn(3) # create my dependent variable which is just some random vector.\n",
    "#print(list_y)\n",
    "\n",
    "for k in range(len(list_x1)):\n",
    "    X[0][k] = list_x1[k]\n",
    "\n",
    "for k in range(len(list_x2)):\n",
    "    X[1][k] = list_x2[k]\n",
    "\n",
    "X = X.transpose()\n",
    "print(\"Matrix containing of my exogeneous Variables X1 and X2 in columns: \\n\",X,\"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Computing the Regression with only x1\n",
    "\"\"\"\n",
    "\n",
    "print(\"Estimates of Regressession Coefficients only including X1\\n\")\n",
    "#list_x1 = sm.add_constant(list_x1)\n",
    "model = sm.OLS(list_y,list_x1).fit()\n",
    "predictions = model.predict()\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Computing the Regression with x1 and x2 included\n",
    "\"\"\"\n",
    "print(\"Estimates of Regressession Coefficients including X1 and X2\\n\")\n",
    "#X = sm.add_constant(X)\n",
    "model = sm.OLS(list_y,X).fit()\n",
    "predictions = model.predict()\n",
    "print(model.summary())\n",
    "\n",
    "X = X.transpose()\n",
    "for k in range(len(list_x3)):\n",
    "    X[1][k] = list_x3[k]\n",
    "\n",
    "X = X.transpose()\n",
    "print(\"Matrix containing of my exogeneous Variables X1 and X3 in columns: \\n\",X,\"\\n\")\n",
    "\n",
    "\n",
    "inner_product = np.dot(list_x1,list_x3) #check whether inner product is zero --> Orthogonality\n",
    "print(\"Inner Product of X1 and X3 = \",inner_product)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
